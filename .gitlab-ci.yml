stages:
  - test
  - build
  - test built
  - package
  - release

variables:
  DEPLOYABLE_BASE_NAME: menger
  DEPLOYABLE_VERSION: 0.3.6
  SBT_IMAGE: sbtscala/scala-sbt:eclipse-temurin-25_36_1.11.7_3.7.3
  DOCKER_IMAGE: registry.gitlab.com/${CI_PROJECT_NAMESPACE}/${CI_PROJECT_NAME}/server
  SCALA_VERSION: 3.7.3
  # OptiX Docker image version: {CUDA}-{OptiX}-{Java}-{sbt}
  OPTIX_DOCKER_VERSION: 12.8-9.0-25-1.11.7

include:
  - template: Code-Quality.gitlab-ci.yml
  - template: Security/SAST.gitlab-ci.yml
  - template: Security/Dependency-Scanning.gitlab-ci.yml
  - template: Security/Secret-Detection.gitlab-ci.yml

# Override code_quality from template to allow failure due to Docker API version mismatch
# in GitLab's DinD service (API 1.41 vs required 1.44). Code quality is validated by
# scalafix in pre-push hooks and semgrep-sast job.
code_quality:
  allow_failure: true

# This job installs sbt by itself. It is somewhat slower than the ones based on scala-sbt below.
# Tests installation from minimal Debian/Ubuntu base images (without CUDA/OptiX).
# Run manually only for documentation purposes - will fail on OptiX JNI compilation.
Test:Debian:
  retry: 1
  tags:
    - nvidia
  parallel:
    matrix:
      - IMAGE:
        - ubuntu:latest
        - ubuntu:22.04
        - debian:stable-slim
        - debian:testing-slim
  image: $IMAGE
  stage: test
  needs: []
  rules:
    - when: manual
      allow_failure: true
  before_script:
    - apt-get -y update
    - apt-get -y upgrade
    - apt-get -y install curl gnupg openjdk-17-jdk # 17 is the latest openjdk version in debian stable
    - echo "deb https://repo.scala-sbt.org/scalasbt/debian all main" > /etc/apt/sources.list.d/sbt.list
    - echo "deb https://repo.scala-sbt.org/scalasbt/debian /" > /etc/apt/sources.list.d/sbt_old.list
    - curl -sL "https://keyserver.ubuntu.com/pks/lookup?op=get&search=0x2EE0EA64E40A89B84B2DF73499E82A75642AC823" | apt-key add
    - apt-get -y update
    - apt-get -y install sbt
    - apt-get -y install mesa-utils x11-xserver-utils xvfb cmake g++
  script:
    # Skip OptiX JNI compilation (no CUDA installed) by setting ENABLE_OPTIX_JNI=false
    - export ENABLE_OPTIX_JNI=false
    - xvfb-run sbt test

# The following ones use a prepared docker image for sbt.
# Validates that installation instructions in docs/INSTALLATION_FROM_SCRATCH.md work
# from a fresh sbt image. Installation takes ~10 minutes (CUDA toolkit download).
# Run manually only to avoid blocking MRs.
Test:SbtImage:
  retry: 1
  image: $SBT_IMAGE
  stage: test
  needs: []
  tags:
    - nvidia
  rules:
    - when: manual
      allow_failure: true
  before_script:
    - apt-get -y update
    - apt-get -y install mesa-utils x11-xserver-utils xvfb cmake g++ curl
    # Install CUDA Toolkit (this takes ~10 minutes)
    - curl -o cuda-keyring_1.1-1_all.deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
    - dpkg -i cuda-keyring_1.1-1_all.deb
    - apt-get -y update
    - apt-get -y install cuda-toolkit-12-8
    # Download OptiX SDK from GitLab Package Registry
    - curl --header "JOB-TOKEN:${CI_JOB_TOKEN}" -o NVIDIA-OptiX-SDK-9.0.0-linux64-x86_64.sh "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/generic/optix-sdk/9.0.0/NVIDIA-OptiX-SDK-9.0.0-linux64-x86_64.sh"
    # Install OptiX SDK
    - chmod +x NVIDIA-OptiX-SDK-9.0.0-linux64-x86_64.sh
    - mkdir -p /usr/local/NVIDIA-OptiX-SDK-9.0.0-linux64-x86_64
    - sh NVIDIA-OptiX-SDK-9.0.0-linux64-x86_64.sh --skip-license --prefix=/usr/local/NVIDIA-OptiX-SDK-9.0.0-linux64-x86_64
    - ln -s /usr/local/NVIDIA-OptiX-SDK-9.0.0-linux64-x86_64 /usr/local/optix
  script:
    # Set environment variables for build (must be in script section to persist)
    - export CUDA_HOME=/usr/local/cuda
    - export OPTIX_ROOT=/usr/local/optix
    - export PATH=$CUDA_HOME/bin:$PATH
    # Run all tests including OptiX JNI
    - xvfb-run sbt test
  artifacts:
    when: always
    reports:
      junit: target/test-reports/**/TEST-*.xml

# Full test suite - Runs on ALL pushes (no rules restrictions)
# Uses pre-built Docker image with CUDA, OptiX, Java 25, and sbt
# IMPORTANT: Requires runner with GPU support configured (see optix-jni/RUNNER_SETUP.md)
Test:Full:
  image: $CI_REGISTRY_IMAGE/optix-cuda:$OPTIX_DOCKER_VERSION
  stage: test
  needs: []
  tags:
    - nvidia  # Requires runner with NVIDIA GPU and nvidia-container-toolkit configured
  variables:
    # Request graphics capability to ensure RTX/OptiX libraries are mounted
    NVIDIA_DRIVER_CAPABILITIES: "graphics,compute,utility"
  # NO rules: section - runs on ALL branch pushes
  before_script:
    # Verify GPU is available - fail fast if not configured
    - nvidia-smi
    # Create missing symlink for RTX core library if needed (OptiX looks for .so.1)
    - |
      if [ -f /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.* ] && [ ! -f /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.1 ]; then
        ln -sf /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.* /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.1
      fi
    # Update library cache
    - ldconfig || true
    # Install xvfb for headless LibGDX tests
    - apt-get -y update
    - apt-get -y install mesa-utils x11-xserver-utils xvfb
  script:
    # Run FULL test suite (both optix-jni and core tests)
    # Java 25, sbt, CUDA 12.8, and OptiX SDK 9.0 are pre-installed in the Docker image
    - xvfb-run sbt test
  after_script:
    # Fix permissions on generated files so they can be cleaned up locally without sudo
    # Docker containers run as root, creating root-owned files that cause permission issues
    - chmod -R 777 target/ || true
    - chmod -R 777 optix-jni/target/ || true
  artifacts:
    when: always
    reports:
      junit:
        - target/test-reports/**/TEST-*.xml
        - optix-jni/target/test-reports/**/TEST-*.xml

# OptiX JNI tests - Uses pre-built Docker image with CUDA, OptiX, Java 25, and sbt
# The image is built and pushed manually (see optix-jni/README.md and optix-jni/Dockerfile)
# IMPORTANT: Requires runner with GPU support configured (see optix-jni/RUNNER_SETUP.md)
Test:OptiXJni:
  image: $CI_REGISTRY_IMAGE/optix-cuda:$OPTIX_DOCKER_VERSION
  stage: test
  needs: []
  tags:
    - nvidia  # Requires runner with NVIDIA GPU and nvidia-container-toolkit configured
  variables:
    # Request graphics capability to ensure RTX/OptiX libraries are mounted
    NVIDIA_DRIVER_CAPABILITIES: "graphics,compute,utility"
  rules:
    - if: "$CI_MERGE_REQUEST_ID"
    - if: $CI_COMMIT_BRANCH == "main"
  before_script:
    # Verify GPU is available - fail fast if not configured
    - nvidia-smi
    # Create missing symlink for RTX core library if needed (OptiX looks for .so.1)
    - |
      if [ -f /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.* ] && [ ! -f /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.1 ]; then
        ln -sf /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.* /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.1
      fi
    # Update library cache
    - ldconfig || true
  script:
    # Run OptiX JNI tests
    # Java 25, sbt, CUDA 12.8, and OptiX SDK 9.0 are pre-installed in the Docker image
    - sbt "project optixJni" test
  after_script:
    # Fix permissions on generated files so they can be cleaned up locally without sudo
    # Docker containers run as root, creating root-owned files that cause permission issues
    - chmod -R 777 optix-jni/target/ || true
  artifacts:
    when: always
    reports:
      junit: optix-jni/target/test-reports/**/TEST-*.xml

# OptiX memory leak detection with compute-sanitizer
# Runs after OptiX JNI tests to verify no GPU memory leaks
Test:ComputeSanitizer:
  image: $CI_REGISTRY_IMAGE/optix-cuda:$OPTIX_DOCKER_VERSION
  stage: test
  needs: []
  tags:
    - nvidia  # Requires runner with NVIDIA GPU
  variables:
    NVIDIA_DRIVER_CAPABILITIES: "graphics,compute,utility"
  rules:
    - if: "$CI_MERGE_REQUEST_ID"
    - if: $CI_COMMIT_BRANCH == "main"
  before_script:
    - nvidia-smi
    # Create missing symlink for RTX core library if needed
    - |
      if [ -f /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.* ] && [ ! -f /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.1 ]; then
        ln -sf /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.* /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.1
      fi
    - ldconfig || true
  script:
    # Build OptiX JNI native library
    - sbt "project optixJni" nativeCompile
    # Compile standalone test
    - cd optix-jni/src/main/native
    - |
      g++ -std=c++17 \
        -I./include -I${CUDA_HOME}/include -I${OPTIX_ROOT}/include \
        -L${CUDA_HOME}/lib64 -L../../../target/native/x86_64-linux/bin \
        standalone_test.cpp -loptixjni -lcudart -o standalone_test
    # Clean any old compute-sanitizer.log
    - rm -f ../../../compute-sanitizer.log
    # Run under compute-sanitizer
    - |
      LD_LIBRARY_PATH=../../../target/native/x86_64-linux/bin:/usr/local/cuda/lib64 \
        compute-sanitizer --tool memcheck ./standalone_test > ../../../compute-sanitizer.log 2>&1 || true
    - cd ../../..
    # Check for memory leaks in the output
    - |
      if [ ! -f compute-sanitizer.log ]; then
        echo "ERROR: compute-sanitizer.log not found!"
        exit 1
      fi
      ERROR_COUNT=$(grep "ERROR SUMMARY:" compute-sanitizer.log | tail -1 | awk '{print $4}')
      echo "compute-sanitizer ERROR SUMMARY - errors found: $ERROR_COUNT"
      if [ "$ERROR_COUNT" != "0" ]; then
        echo "Memory leaks or errors detected!"
        cat compute-sanitizer.log
        exit 1
      fi
  after_script:
    - chmod -R 777 optix-jni/target/ || true
  artifacts:
    when: always
    paths:
      - compute-sanitizer.log

# OptiX host memory leak detection with Valgrind
# Runs standalone C++ test (bypasses JVM) to check for host-side memory leaks
Test:Valgrind:
  image: $CI_REGISTRY_IMAGE/optix-cuda:$OPTIX_DOCKER_VERSION
  stage: test
  needs: []
  tags:
    - nvidia  # Requires runner with NVIDIA GPU
  variables:
    NVIDIA_DRIVER_CAPABILITIES: "graphics,compute,utility"
  rules:
    - if: "$CI_MERGE_REQUEST_ID"
    - if: $CI_COMMIT_BRANCH == "main"
  before_script:
    - nvidia-smi
    # Install Valgrind
    - apt-get update && apt-get install -y valgrind cmake
    # Create missing symlink for RTX core library if needed
    - |
      if [ -f /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.* ] && [ ! -f /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.1 ]; then
        ln -sf /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.* /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.1
      fi
    - ldconfig || true
  script:
    # Build OptiX JNI native library
    - sbt "project optixJni" nativeCompile
    # Compile standalone test
    - cd optix-jni/src/main/native
    - |
      g++ -std=c++17 \
        -I./include -I${CUDA_HOME}/include -I${OPTIX_ROOT}/include \
        -L${CUDA_HOME}/lib64 -L../../../target/native/x86_64-linux/bin \
        standalone_test.cpp -loptixjni -lcudart -o standalone_test
    # Clean any old valgrind.log
    - rm -f ../../../valgrind.log
    # Run under Valgrind
    - |
      LD_LIBRARY_PATH=../../../target/native/x86_64-linux/bin:/usr/local/cuda/lib64 \
        valgrind --leak-check=full --error-exitcode=1 \
        --errors-for-leak-kinds=definite,indirect \
        --suppressions=../../../../valgrind.supp \
        ./standalone_test > ../../../valgrind.log 2>&1 || true
    - cd ../../..
    # Check for memory leaks (only "definitely lost" and "indirectly lost" are our bugs)
    - |
      if [ ! -f valgrind.log ]; then
        echo "ERROR: valgrind.log not found!"
        exit 1
      fi
      DEFINITELY_LOST=$(grep "definitely lost:" valgrind.log | awk '{print $4}' | sed 's/,//g' || echo "0")
      INDIRECTLY_LOST=$(grep "indirectly lost:" valgrind.log | awk '{print $4}' | sed 's/,//g' || echo "0")
      echo "Valgrind - definitely lost: ${DEFINITELY_LOST} bytes"
      echo "Valgrind - indirectly lost: ${INDIRECTLY_LOST} bytes"
      if [ "$DEFINITELY_LOST" != "0" ] || [ "$INDIRECTLY_LOST" != "0" ]; then
        echo "Memory leaks detected!"
        cat valgrind.log
        exit 1
      fi
  after_script:
    - chmod -R 777 optix-jni/target/ || true
  artifacts:
    when: always
    paths:
      - optix-jni/valgrind.log

# OptiX sphere rendering integration tests
# Tests both packaged distribution and sbt run with OptiX enabled
Test:OptiXIntegration:
  image: $CI_REGISTRY_IMAGE/optix-cuda:$OPTIX_DOCKER_VERSION
  stage: test
  needs: []
  tags:
    - nvidia
  timeout: 20m  # Fail fast on hangs, retry will recover
  retry: 2      # 1 initial + 2 retries = 3 attempts max = 60m total (GitLab max retry=2)
  variables:
    NVIDIA_DRIVER_CAPABILITIES: "graphics,compute,utility"
  before_script:
    - apt-get -y update
    - apt-get -y install mesa-utils x11-xserver-utils xvfb unzip
    # Create missing symlink for RTX core library if needed
    - |
      if [ -f /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.* ] && [ ! -f /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.1 ]; then
        ln -sf /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.* /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.1
      fi
    - ldconfig || true
  script:
    # Test sbt run with OptiX sphere rendering
    - xvfb-run -a sbt "run --optix --sponge-type sphere --timeout 0.1 --radius 0.5"
    # Build and test packaged distribution
    - sbt "Universal / packageBin"
    - VERSION=$(grep 'version :=' build.sbt | cut -d '"' -f 2)
    - unzip -oq ./target/universal/menger-${VERSION}.zip
    - export LD_LIBRARY_PATH=/usr/local/cuda/lib64
    - xvfb-run -a ./menger-${VERSION}/bin/menger --optix --sponge-type sphere --timeout 0.1
  after_script:
    # Clean up permissions for Docker artifacts
    - chmod -R 777 target/ || true
    - chmod -R 777 optix-jni/target/ || true

CheckCoverage:
  image: $CI_REGISTRY_IMAGE/optix-cuda:$OPTIX_DOCKER_VERSION
  stage: test
  needs: []
  rules:
    - if: "$CI_MERGE_REQUEST_ID"
    - if: $CI_COMMIT_BRANCH == "main"
  before_script:
    - apt-get -y update
    - apt-get -y install bc mesa-utils x11-xserver-utils xvfb curl
  script:
    - 'curl -o coverage.log --location --header "PRIVATE-TOKEN: $GITLAB_ACCESS_TOKEN" "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/jobs/artifacts/${CI_COMMIT_REF_NAME}/raw/coverage.log?job=${CI_JOB_NAME}"'
    - . coverage.log || true
    - statement_rate_old=${statement_rate:-0}
    - branch_rate_old=${branch_rate:-0}
    - xvfb-run sbt clean coverage test || true
    - sbt coverageReport
    - REPORT=$(head -n 2 target/scala-3.*.*/scoverage-report/scoverage.xml | tail -n 1 | xargs)
    - for word in $REPORT; do echo $word; done | grep rate | tr - _ > coverage.log
    - . coverage.log
    - echo "statement_rate_old=$statement_rate_old, statement_rate=$statement_rate"
    - echo "branch_rate_old=$branch_rate_old, branch_rate=$branch_rate"
    - if [ $(echo "$branch_rate_old > $branch_rate" | bc -l) -eq 1 ]; then echo "branch rate decreased from $branch_rate_old to $branch_rate"; fi
    - if [ $(echo "$statement_rate_old > $statement_rate" | bc -l) -eq 1 -a $(echo "$statement_rate < 0.9" | bc -l) -eq 1 ]; then exit 1; fi
  artifacts:
    when: always
    reports:
      junit: target/test-reports/**/TEST-*.xml
    paths:
      - coverage.log
      - target/scala-${SCALA_VERSION}/scoverage-report/

Scalafix:
  image: $CI_REGISTRY_IMAGE/optix-cuda:$OPTIX_DOCKER_VERSION
  stage: test
  needs: []
  rules:
    - if: "$CI_MERGE_REQUEST_ID"
    - if: $CI_COMMIT_BRANCH == "main"
  script:
    # Scalafix only checks Scala code style, no GPU needed
    - sbt "scalafix --check"
  allow_failure: false

sonarcloud-check:
  variables:
    SONAR_USER_HOME: "${CI_PROJECT_DIR}/.sonar"  # Defines the location of the analysis task cache
    GIT_DEPTH: "0"  # Tells git to fetch all the branches of the project, required by the analysis task
  rules:
    - if: "$SONAR_TOKEN"
  image:
    name: sonarsource/sonar-scanner-cli:latest
    entrypoint: [""]
  cache:
    key: "${CI_JOB_NAME}"
    paths:
      - .sonar/cache
  script:
    - sonar-scanner

pages:
  image: ubuntu:latest
  stage: package
  needs:
    - CheckCoverage
    - ScalaVersionConsistent
  rules:
    - if: "$CI_MERGE_REQUEST_ID"
  script:
    - mv target/scala-${SCALA_VERSION}/scoverage-report/ public/
  artifacts:
    paths:
      - public

Run:UseDocker:
  image: $CI_REGISTRY_IMAGE/optix-cuda:$OPTIX_DOCKER_VERSION
  stage: test
  needs: []
  timeout: 20m  # Fail fast on hangs, retry will recover
  retry: 2      # 1 initial + 2 retries = 3 attempts max = 60m total (GitLab max retry=2)
  before_script:
    - apt-get -y update
    - apt-get -y install mesa-utils x11-xserver-utils xvfb
  script:
    - xvfb-run -a sbt "run --timeout 0.1 --level 1 --lines --sponge-type cube"
    - xvfb-run -a sbt "run --timeout 0.1 --level 1 --lines"
    - xvfb-run -a sbt "run --timeout 0.1 --level 4"
    - xvfb-run -a sbt "run --timeout 0.1 --sponge-type tesseract"
    - xvfb-run -a sbt "run --timeout 0.1 --level 1 --sponge-type tesseract-sponge"
    - xvfb-run -a sbt "run --timeout 0.1 --level 2 --sponge-type tesseract-sponge-2"
    - xvfb-run -a sbt "run --level 1 --sponge-type tesseract-sponge-2 --animate frames=5:rot-y-w=0-90:rot-y=0-30"
    - xvfb-run -a sbt "run --level 1 --sponge-type tesseract-sponge-2 --animate frames=5:rot-y-w=0-90 --save-name menger%04d.png"
    - test -f menger0000.png
    - test -f menger0004.png
    - for TYPE in cube square tesseract-sponge tesseract-sponge-2; do xvfb-run -a sbt "run --level 1.5 --timeout 0.1 --sponge-type $TYPE" || exit 1; done


CheckRunTime:
  image: $CI_REGISTRY_IMAGE/optix-cuda:$OPTIX_DOCKER_VERSION
  stage: test
  needs: []
  tags:
    - nvidia
  before_script:
    - apt-get -y update
    - apt-get -y install bc time mesa-utils x11-xserver-utils xvfb
  script:
    - sbt compile
    # Test if OPTIX_ROOT is needed for running (unset to check)
    - unset OPTIX_ROOT
    - /usr/bin/time -f %U -o runtime.log xvfb-run sbt "run --timeout 0.1"
    - echo "$(<runtime.log) > $TEST_RUN_MAX_RUNNING_TIME"
    - if [ $(echo "$(<runtime.log) > $TEST_RUN_MAX_RUNNING_TIME" | bc -l) -eq 1 ]; then exit 1; fi
  artifacts:
    paths:
      - runtime.log

TagIsNewAndConsistent:
  stage: test
  image: ubuntu:latest
  rules:
    - if: "$CI_MERGE_REQUEST_ID"
  before_script:
    - apt-get -y update
    - apt-get -y install git
  script:
    - VERSION_SBT=$(egrep 'version := ".*"' build.sbt | cut -d \" -f 2)
    - test -n "$VERSION_SBT"
    - echo $VERSION_SBT
    - VERSIONS_CI=$(egrep 'DEPLOYABLE_VERSION.*' .gitlab-ci.yml | head -n 1 | cut -d ':' -f 2 | xargs)
    - test -n "$VERSIONS_CI"
    - echo $VERSIONS_CI
    - test "$VERSION_SBT" = "$VERSIONS_CI"
    - git tag | ( ! grep "^${VERSION_SBT}\$" )

ScalaVersionConsistent:
  stage: test
  image: ubuntu:latest
  rules:
    - if: "$CI_MERGE_REQUEST_ID"
  script:
    - SCALA_VERSION=$(egrep 'scalaVersion := ".*"' build.sbt | cut -d \" -f 2 | xargs) || true
    - >
      GITLAB_SCALA_VERSION=$(egrep 'SCALA_VERSION. .*' .gitlab-ci.yml | head -n 1 | cut -d: -f 2 | xargs) || true
    - if [ "$SCALA_VERSION" = "$GITLAB_SCALA_VERSION" ]
    - then
    - echo "Scala version \"${SCALA_VERSION}\""
    - else
    - echo "Scala in build.sbt \"${SCALA_VERSION}\", in .gitlab-ci.yml \"${GITLAB_SCALA_VERSION}\""
    - exit 1
    - fi

ChangelogIsUpdated:
  stage: test
  image: ubuntu:latest
  rules:
    - if: "$CI_MERGE_REQUEST_ID"
  script:
    - test -f CHANGELOG.md || exit 0
    - VERSION=$(egrep 'version := ".*"' build.sbt | cut -d \" -f 2)
    - test -n "$VERSION"
    - fgrep "## [$VERSION]" CHANGELOG.md
    - fgrep "...$VERSION" CHANGELOG.md
    - echo $CI_MERGE_REQUEST_TITLE | grep '^Draft:\|^WIP:' ||
      fgrep "## [$VERSION] - $(date +%Y-%m-%d)" CHANGELOG.md

BuildDeployable:
  image: $CI_REGISTRY_IMAGE/optix-cuda:$OPTIX_DOCKER_VERSION
  stage: build
  needs: []
  tags:
    - nvidia
  script:
    # Build deployable package with full OptiX JNI
    - sbt "Universal / packageBin"
    - mv target/universal/${DEPLOYABLE_BASE_NAME}-${DEPLOYABLE_VERSION}.zip .
  artifacts:
    paths:
      - menger-*.*.*.zip

CreateTag:
  stage: release
  image: alpine:latest
  rules:
    - if: $CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE != "schedule"
      when: on_success
  before_script:
    - apk update
    - apk add git
    - git config user.email "${GITLAB_USER_EMAIL}"
    - git config user.name "${GITLAB_USER_NAME}"
  script:
    - VERSION_SBT=$(egrep 'version := ".*"' build.sbt | cut -d \" -f 2)
    - echo "**** Tagging release as version $VERSION_SBT"
    - git remote add tag-origin https://oauth2:${GITLAB_ACCESS_TOKEN}@gitlab.com/${CI_PROJECT_PATH}
    - git tag -a "${VERSION_SBT}" -m "Released $(date +%Y-%m-%d)"
    - git push tag-origin "${VERSION_SBT}"

Upload:
  stage: release
  image: registry.gitlab.com/gitlab-org/release-cli:latest
  needs:
    - job: BuildDeployable
      artifacts: true
  rules:
    - if: $CI_COMMIT_TAG
  allow_failure: true
  before_script:
    - apk update
    - apk add curl
  script:
    - export DEPLOYABLE_ZIP_FILE=${DEPLOYABLE_BASE_NAME}-${DEPLOYABLE_VERSION}.zip
    - echo curl --header "JOB-TOKEN $CI_JOB_TOKEN" --upload-file ${DEPLOYABLE_ZIP_FILE} "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/generic/${DEPLOYABLE_ZIP_FILE}"
    - 'curl --header "JOB-TOKEN: $CI_JOB_TOKEN" --upload-file ${DEPLOYABLE_ZIP_FILE} "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/generic/${DEPLOYABLE_ZIP_FILE}"'

PushToGithub:
  stage: release
  image: alpine:latest
  rules:
    - if: "$CI_COMMIT_TAG"
      when: on_success
  needs:
    - Test:SbtImage
    - Run:UseDocker
    - CheckRunTime
  before_script:
    - apk update
    - apk add openssh-client git sshpass
    - eval $(ssh-agent -s)
    - echo "$GITHUB_SSH_PRIVATE_KEY" | tr -d '\r' | ssh-add - > /dev/null
    - mkdir -p ~/.ssh
    - chmod 700 ~/.ssh
    - ssh-keyscan github.com >> ~/.ssh/known_hosts
    - chmod 644 ~/.ssh/known_hosts
    - ssh -T git@github.com 2>&1 || true
    - git config user.email "${GITLAB_USER_EMAIL}"
    - git config user.name "${GITLAB_USER_NAME}"
    - git config pull.rebase true
  script:
    - git remote add github git@github.com:lene/menger.git
    - git remote show github
    - BRANCH=${CI_COMMIT_BRANCH:-main}
    - git fetch origin $BRANCH
    - git checkout $BRANCH
    - git rebase --abort || true
    - git pull github $BRANCH || git reset --hard origin/$BRANCH
    - git push --force github $BRANCH
    - git push --force github $CI_COMMIT_TAG

CreateGithubRelease:
  stage: release
  needs:
    - PushToGithub
  image: alpine:latest
  rules:
    - if: "$CI_COMMIT_TAG"
      when: on_success
  allow_failure: true
  before_script:
    - apk update
    - apk add curl
  variables:
    RELEASE_API_URL: "https://api.github.com/repos/lene/menger/releases"
    DESCRIPTION: "Full Changelog: https://github.com/lene/menger/blob/${CI_COMMIT_TAG}/CHANGELOG.md"
  script:
    - POST_DATA='{
      "tag_name":"'${CI_COMMIT_TAG}'",
      "target_commitish":"main",
      "name":"'${CI_COMMIT_TAG}'",
      "body":"'${FULL_DESCRIPTION}${DESCRIPTION}'",
      "draft":false,
      "prerelease":false,
      "generate_release_notes":false
      }'
    - echo $API_URL
    - echo $POST_DATA
    - 'curl -L -X POST 
         -H "Accept: application/vnd.github+json" 
         -H "X-GitHub-Api-Version: 2022-11-28" 
         -H "Authorization: Bearer ${GITHUB_API_TOKEN}"
         ${RELEASE_API_URL} -d "${POST_DATA}"'

CreateGitlabRelease:
  stage: release
  image: registry.gitlab.com/gitlab-org/release-cli:latest
  needs:
    - job: BuildDeployable
      artifacts: true
  rules:
    - if: $CI_COMMIT_TAG
  script:
    - echo 'running release_job'
  release:
    name: 'Release $CI_COMMIT_TAG'
    description: 'Created using the release-cli'
    tag_name: '$CI_COMMIT_TAG'
    ref: '$CI_COMMIT_TAG'
